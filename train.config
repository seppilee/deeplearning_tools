# model option
model_type = seq2seq  # lm, seq2seq, seqtagge
param_init = 0.1 # 0.1

# Sequence to Sequence option
enc_layers = 4
dec_layers = 4
rnn_size = 512
rnn_type = LSTM #LSTM, GRU
src_word_vec_siz = 256
tgt_word_vec_size = 256
pre_word_vecs_enc = ''
pre_word_vecs_enc = ''
fix_word_vecs_enc = false #false, true, pretrained
fix_word_vecs_dec = false #false, true, pretrained
feat_merge = concat #concat, sum
feat_vec_exponent = 0.7 #0.7
feat_vec_size = 20

dropout = 0.3
dropout_input = false  #false
dropout_words = 0      #0
dropout_type = naive   #naive, variational

residual = false
bridge = copy #copy, dense, dense_nonlinear, non
input_feed = true  #true

scheduled_sampling = 1
scheduled_sampling_scope = token #token, sentence
scheduled_sampling_decay_type = linear #linear, invsigmoid
scheduled_sampling_decay_rate = 0
attention = global #none, global

brnn_merge = sum #concat, sum
pdbrnn_reduction = 2 #2
pdbrnn_merge = concat #concat, sum

global_attention = general #general, dot, concat

# CNN encoder option
encoder_type = cnn #rnn, brnn, dbrnn, pdbrnn, gnmt, cnn
cnn_layers = 2     #2
cnn_kernel = 3     #3
cnn_size = 512     #500
use_pos_emb = true #true
max_pos = 50       #50

# optimization
optim = sgd #sgd, adagrad, adadelta, adam
learning_rate = 1 #sgd = 1, adagrad = 0.1, adam = 0.0002
min_learning_rate = 0 #0
max_grad_norm = 5
start_decay_at = 10  #9
learning_rate_decay = 0.7 # 0.7
max_batch_size = 64
uneven_batches = false #false
start_decay_score_delta = 0 #0
decay = default #default, epoch_only, score_only
decay_method = default #default, restart

# report
save_every_epochs = 1  #1
curriculum = 0         #0
report_every = 50      # 50
validation_metric = ppl #perplexity, loss, bleu, ter, dlratio
save_validation_translation_every = 0 # 0
update_vocab = none    # none, replace, merge
save_every = 10000
start_epoch = 1
start_iteration = 1
end_epoch = 18
gpuid = 1
ddmax_batch_size = 64
async_parallel_minbatch = 1000
async_parallel = false

# Saver options
# train_from = ''
# continue = 1 #0

data       = 'bin-train.t7'
save_model = 'model'

#Cuda options
gpuid = 1
fallback_to_cpu = 0
fp16 = false
no_nccl = false

#HookManager options
hook_file = '' #Pointer to a lua file registering hooks for the current process

#Logger options
log_file = ''
disable_logs = false
log_level = INFO #DEBUG, INFO, WARNING, ERROR, NONE

#Other options
disable_mem_optimization = false
profiler = false
seed = 3435
